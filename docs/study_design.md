# Study Design Summary


**Objective:** Evaluate whether GPT-based explanations improve novice programmersâ€™ understanding and debugging accuracy.

**Participants:** 5 volunteers with <1 year Python experience.  
**Methodology:**  
- Each participant completed two sets of short code-comprehension tasks:  
  one with AI feedback, one without.  
- Collected completion time, self-explanation clarity, and Likert-scale usefulness ratings.  

**Preliminary Findings:**  
Participants using AI explanations showed faster task completion and better ability
to articulate reasoning. Feedback indicated that "debug hint" mode was more useful
for identifying logical errors than syntax mistakes.  

**Conclusion:**  
The prototype demonstrated the feasibility of integrating generative AI into educational tools
that emphasize reasoning and responsible use rather than automation.
